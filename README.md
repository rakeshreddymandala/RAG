# ğŸš€ FAISS RAG-Based Medical Chatbot

## ğŸ“Œ Overview
This project implements a **Retrieval-Augmented Generation (RAG)** chatbot using **FAISS** for vector search and **Mistral-7B** as the LLM. The chatbot is designed to answer **medical-related queries** by retrieving relevant information from a **medical document database** and generating structured, informative responses.

## ğŸ”¥ Features
- **FAISS-Based Vector Search**: Efficient retrieval of medical documents.
- **Hugging Face Embeddings**: Uses `sentence-transformers/paraphrase-MiniLM-L3-v2` for vector embeddings.
- **LLM (Mistral-7B-Instruct-v0.3)**: Hosted on Hugging Face Inference API.
- **Custom Prompt Engineering**: Ensures structured, easy-to-read responses.
- **Medical Query Classification**: Filters out non-medical queries.
- **Streamlit UI**: Interactive chat-based interface.

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**
- **FAISS** (Facebook AI Similarity Search)
- **Hugging Face Transformers & Inference API**
- **LangChain** (for RAG implementation)
- **Streamlit** (for UI)

## âš™ï¸ Installation
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/your-username/faiss-rag-medical-chatbot.git
cd faiss-rag-medical-chatbot
```

### **2ï¸âƒ£ Create a Virtual Environment**
```sh
python -m venv venv
source venv/bin/activate  # For Mac/Linux
venv\Scripts\activate    # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```sh
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Hugging Face API Token**
Get your Hugging Face API key from [Hugging Face](https://huggingface.co/settings/tokens) and set it as an environment variable:
```sh
export HF_TOKEN="your-huggingface-api-key"  # Mac/Linux
set HF_TOKEN="your-huggingface-api-key"  # Windows
```

## ğŸš€ Running the Chatbot
```sh
streamlit run app.py
```
This will start a local server. Open the provided **localhost URL** in your browser.

## ğŸ“œ Project Workflow
### **Phase 1: Create Memory**
âœ… Load medical documents â âœ… Chunking â âœ… Create vector embeddings â âœ… Store in FAISS

### **Phase 2: Connect Memory with LLM**
âœ… Load FAISS â âœ… Use Mistral-7B â âœ… Implement RAG-based Retrieval

### **Phase 3: UI Development**
âœ… Build Streamlit Chatbot UI â âœ… Integrate RAG pipeline â âœ… Deploy

## ğŸ–¥ï¸ UI Preview
The chatbot interface is built with **Streamlit** and provides:
- âœ… A text input box for medical queries.
- âœ… AI-generated structured medical responses.
- âœ… Display of retrieved medical sources.

## ğŸ¥ Example Query
**User:** "What are the symptoms of diabetes?"

**Chatbot Response:**
```
ğŸ’¡ **Answer:**
- Increased thirst and frequent urination
- Extreme hunger
- Unexplained weight loss
- Fatigue
- Blurred vision

âš ï¸ Please consult a doctor for medical advice.
```

## ğŸ“‚ Project Structure
```
ğŸ“¦ faiss-rag-medical-chatbot
â”œâ”€â”€ ğŸ“‚ vectorstore/        # FAISS database
â”œâ”€â”€ ğŸ“œ app.py              # Streamlit UI
â”œâ”€â”€ ğŸ“œ rag_pipeline.py     # RAG implementation
â”œâ”€â”€ ğŸ“œ requirements.txt    # Dependencies
â”œâ”€â”€ ğŸ“œ README.md           # Project documentation
â””â”€â”€ ğŸ“œ .gitignore          # Ignore unnecessary files
```

## ğŸ› ï¸ Future Improvements
- âœ… Improve the **retrieval accuracy** with better embeddings.
- âœ… Add **more medical documents** to enhance AI knowledge.
- âœ… Deploy on **Hugging Face Spaces or AWS**.

## ğŸ’¡ Credits
- **FAISS**: Meta AI
- **Mistral-7B**: Hugging Face
- **Streamlit**: Open-source UI framework

## ğŸ“œ License
This project is licensed under the **MIT License**.

---
_â­ If you find this project useful, consider giving it a star on GitHub!_ ğŸŒŸ

